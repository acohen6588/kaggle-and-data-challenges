{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_images', '.Rhistory', 'InstallPackages.R', 'breed_labels.csv', '.DS_Store', 'test', 'train_metadata', 'color_labels.csv', 'test_sentiment', 'test_metadata', 'GitStuff', 'README.md', 'train_sentiment', 'pet-adoption-eda-and-preliminary-model.Rmd', 'train.csv', '.git', 'train_images', 'state_labels.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json\n",
    "import PIL\n",
    "import nltk\n",
    "#nltk.download('vader_lexicon')\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"/Users/andrewcohen/Desktop/KaggleData\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/Users/andrewcohen/Desktop/KaggleData/train.csv\")\n",
    "test_df = pd.read_csv(\"/Users/andrewcohen/Desktop/KaggleData/test/test.csv\")\n",
    "breeds_df = pd.read_csv(\"/Users/andrewcohen/Desktop/KaggleData/breed_labels.csv\")\n",
    "dog_cat = {1: 'dog', 2: 'cat'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def mix_breed(row):\n",
    "    b1 = row['Breed1']\n",
    "    b2 = row['Breed2']\n",
    "    if any([b1 == 307, b2 == 307]) or all([b1 > 0, b2 > 0, b1 != b2]):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def new_breed1(row):\n",
    "    b1 = row['Breed1']\n",
    "    b2 = row['Breed2']\n",
    "    if b1 == b2:\n",
    "        if b1 in [0, 307]:\n",
    "            return -1\n",
    "        else:\n",
    "            return b1       \n",
    "    elif b1 == 307 or b2 == 307:\n",
    "        if b1 == 307 and b2 != 0:\n",
    "            return b2\n",
    "        elif b2 == 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return b1 if b1 != 0 else -1\n",
    "    else:\n",
    "        if b1 == 0:\n",
    "            return b2\n",
    "        else:\n",
    "            return b1\n",
    "        \n",
    "def new_breed2(row):\n",
    "    b1 = row['Breed1']\n",
    "    b2 = row['Breed2']\n",
    "    if b1 == b2:\n",
    "        return -1 if b1 in [0, 307] else 0      \n",
    "    elif b1 == 307 or b2 == 307:\n",
    "        return -1\n",
    "    else:\n",
    "        if b1 !=0  and b2 != 0:\n",
    "            return b2\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "train_df['Mixed'] = train_df.apply(lambda row: mix_breed(row), axis=1)\n",
    "train_df['NewBreed1'] = train_df.apply(lambda row: new_breed1(row), axis=1)\n",
    "train_df['NewBreed2'] = train_df.apply(lambda row: new_breed2(row), axis=1)\n",
    "test_df['Mixed'] = test_df.apply(lambda row: mix_breed(row), axis=1)\n",
    "test_df['NewBreed1'] = test_df.apply(lambda row: new_breed1(row), axis=1)\n",
    "test_df['NewBreed2'] = test_df.apply(lambda row: new_breed2(row), axis=1)\n",
    "\n",
    "def has_name(name):\n",
    "    if 'no name' in name.lower():\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "train_df['HasName'] = train_df.apply(lambda row: has_name(str(row)), axis=1)\n",
    "test_df['HasName'] = test_df.apply(lambda row: has_name(str(row)), axis=1)\n",
    "\n",
    "def get_top_labann(lab_anns):\n",
    "    scores = np.array([a['score'] for a in lab_anns])\n",
    "    tops = scores.argsort()\n",
    "    return {'top_annotation': lab_anns[tops[-1]]['description'], 'annot_score': lab_anns[tops[-1]]['score']}\n",
    "\n",
    "def get_image_size(im):\n",
    "    return {'im_w': im.size[0], 'im_d': im.size[1], '#_pix': np.product(im.size)}\n",
    "\n",
    "def get_im_meta(petID, df, sample):\n",
    "    if sample == 'train':\n",
    "        fp_p = \"../input/train_images/\"\n",
    "        fp_j = \"../input/train_metadata/\"\n",
    "    else:\n",
    "        fp_p = \"../input/test_images/\"\n",
    "        fp_j = \"../input/test_metadata/\"\n",
    "    pet_type = int(df[df['PetID']==petID]['Type'])\n",
    "    possible_breeds = set([x.lower() for x in breeds_df[breeds_df['Type']==pet_type]['BreedName'].values])\n",
    "    try:\n",
    "        with open(fp_j+petID+'-1.json', 'r', encoding='iso-8859-1') as im_meta:\n",
    "            im_data_m = json.loads(im_meta.read())\n",
    "        img = PIL.Image.open(fp_p+petID+'-1.jpg')\n",
    "        res = {'PetID': petID}\n",
    "        try:\n",
    "            lab_anns = get_top_labann(im_data_m['labelAnnotations'])\n",
    "            lab_a = lab_anns['top_annotation'].lower()\n",
    "            lab_anns['top_annotation'] = int(any([lab_a in possible_breeds, dog_cat[pet_type] in lab_a]))\n",
    "        except KeyError:\n",
    "            lab_anns = {'top_annotation': -1, 'annot_score': -1}\n",
    "        for x in lab_anns:\n",
    "            res[x] = lab_anns[x]\n",
    "        im_s = get_image_size(img)\n",
    "        for x in im_s:\n",
    "            res[x] = im_s[x]\n",
    "        return res\n",
    "    except FileNotFoundError:\n",
    "        return {'PetID': petID, 'im_w': -1, 'im_d': -1, '#_pix': -1,  'top_annotation': -1, 'annot_score': -1}\n",
    "    \n",
    "meta_data_train = []\n",
    "for petID in train_df['PetID'].values:\n",
    "    meta_data_train.append(get_im_meta(petID, train_df, 'train'))\n",
    "meta_df_train = pd.DataFrame(meta_data_train)\n",
    "cols_to_use = train_df.columns.difference(meta_df_train.columns)\n",
    "train_df = pd.concat([train_df[cols_to_use], meta_df_train], axis=1)\n",
    "\n",
    "meta_data_test = []\n",
    "for petID in test_df['PetID'].values:\n",
    "    meta_data_test.append(get_im_meta(petID, test_df, 'test'))\n",
    "meta_df_test = pd.DataFrame(meta_data_test)\n",
    "cols_to_use = test_df.columns.difference(meta_df_test.columns)\n",
    "test_df = pd.concat([test_df[cols_to_use], meta_df_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewcohen/anaconda3/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "#Sentiment Analysis    \n",
    "from nltk.sentiment import vader\n",
    "vader_sent = vader.SentimentIntensityAnalyzer()\n",
    "\n",
    "name_sent_tr = []\n",
    "for name in train_df[\"Name\"].values:\n",
    "    if has_name(str(name)):\n",
    "        name_sent_tr.append(vader_sent.polarity_scores(str(name)))\n",
    "    else:\n",
    "        name_sent_tr.append({'compound': 0, 'neg': 0.0, 'neu': 0.0, 'pos': 0})\n",
    "        \n",
    "name_sent_ts = []\n",
    "for name in test_df[\"Name\"].values:\n",
    "    if has_name(str(name)):\n",
    "        name_sent_ts.append(vader_sent.polarity_scores(str(name)))\n",
    "    else:\n",
    "        name_sent_ts.append({'compound': 0, 'neg': 0.0, 'neu': 0.0, 'pos': 0})\n",
    "        \n",
    "\n",
    "name_feat_tr = pd.DataFrame(name_sent_tr)\n",
    "name_feat_ts = pd.DataFrame(name_sent_ts)\n",
    "\n",
    "train_df = pd.concat((name_feat_tr, train_df), axis=1)\n",
    "test_df = pd.concat((name_feat_ts, test_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4a51b71ff0ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m X = train_df[['Type', 'Age', 'NewBreed1', 'NewBreed2', 'Mixed', 'Gender', 'Color1', 'Color2',\n\u001b[0m\u001b[1;32m      2\u001b[0m        \u001b[0;34m'Color3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'MaturitySize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'FurLength'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Vaccinated'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dewormed'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m        \u001b[0;34m'Sterilized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Health'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Quantity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Fee'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'State'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'HasName'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'compound'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0;34m'neg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'neu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'VideoAmt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'PhotoAmt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'top_annotation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'annot_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'im_w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        'im_d', '#_pix']].values\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "X = train_df[['Type', 'Age', 'NewBreed1', 'NewBreed2', 'Mixed', 'Gender', 'Color1', 'Color2',\n",
    "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
    "       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'HasName', 'compound',\n",
    "       'neg', 'neu', 'pos', 'VideoAmt', 'PhotoAmt','top_annotation', 'annot_score', 'im_w',\n",
    "       'im_d', '#_pix']].values\n",
    "y = train_df['AdoptionSpeed'].values\n",
    "\n",
    "\n",
    "\n",
    "X_tr = test_df[['Type', 'Age', 'NewBreed1', 'NewBreed2', 'Mixed', 'Gender', 'Color1', 'Color2',\n",
    "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
    "       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'HasName', 'compound',\n",
    "       'neg', 'neu', 'pos', 'VideoAmt', 'PhotoAmt', 'top_annotation', 'annot_score', 'im_w',\n",
    "       'im_d', '#_pix']].values\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "#clf = GradientBoostingClassifier(n_estimators=500, learning_rate=0.07, max_features=1,\n",
    "#                                max_depth=4)\n",
    "#clf.fit(X,y)\n",
    "\n",
    "#test_df['AdoptionSpeed'] = clf.predict(X_tr)\n",
    "\n",
    "lgb_train = lgb.Dataset(X, y)\n",
    "params = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 5,\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.01 ,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 50,\n",
    "        'n_estimators': 700,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 1,\n",
    "        'bagging_seed': 1,\n",
    "        'feature_fraction': 1,\n",
    "        'feature_fraction_seed': 1,\n",
    "        'max_bin': 512,\n",
    "        'metric' : 'multi_error'\n",
    "    }\n",
    "\n",
    "clf = lgb.train(params, train_set = lgb_train, verbose_eval=100)\n",
    "test_df['AdoptionSpeed'] = clf.predict(X_tr).argmax(axis=1)\n",
    "\n",
    "test_df[['PetID','AdoptionSpeed']].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
